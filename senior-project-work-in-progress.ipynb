{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#read data set 1 and name it df\ndf = pd.read_csv ('../input/mobility-report/Global_Mobility_Report -filtered.csv')\n#print(df)\n#read data set 2 and name it df2\ndf2 = pd.read_csv ('../input/owid-covid/owid-covid-data2.csv')\n#print(df2)\n#merge df and df2 usiong method \"outer\" so that no data is ommitted from any of the 2 data frames\ndf3= pd.merge(left=df, right=df2, on=\"date\")\n\n#df3.a.fillna(value=0, inplace=True) # This fills all the null values in the columns with 0\n\n#print(df3)\n\n#Export the merged data frame to a csv file\n\ndf3.to_csv('mergedDataFrame.csv',index=False)    \n\n#load specifc columns of the merged dataFrame by name\ndf6 = pd.read_csv(\n    './mergedDataFrame.csv',\n    header = 0,\n    sep = ',',\n    usecols = lambda x:x.lower() in [\"retail_and_recreation_percent_change_from_baseline\", \"grocery_and_pharmacy_percent_change_from_baseline\", \"parks_percent_change_from_baseline\", \"transit_stations_percent_change_from_baseline\", \"workplaces_percent_change_from_baseline\", \"date\", \"stringency_index\", \"new_cases\"]\n)\ndf6.to_csv('workingCSV.csv', index=False)\nprint(df6)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-01T01:44:02.908126Z","iopub.execute_input":"2022-04-01T01:44:02.908492Z","iopub.status.idle":"2022-04-01T01:44:22.257308Z","shell.execute_reply.started":"2022-04-01T01:44:02.90838Z","shell.execute_reply":"2022-04-01T01:44:22.256405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\nseries = TimeSeries.from_csv('./workingCSV.csv',time_col='date')\nseries.plot()\n# Create training and validation sets:\ntrain, val = series.split_after(0.8)\n# Normalize the time series (note: we avoid fitting the transformer on the validation set)\ntransformer = Scaler()\ntrain_transformed = transformer.fit_transform(train)\nval_transformed = transformer.transform(val)\nseries_transformed = transformer.transform(series)\n# create month and year covariate series\nyear_series = datetime_attribute_timeseries(\n    pd.date_range(start=series.start_time(), freq=series.freq_str, periods=1000),\n    attribute=\"year\",\n    one_hot=False,\n)\nyear_series = Scaler().fit_transform(year_series)\nmonth_series = datetime_attribute_timeseries(\n    year_series, attribute=\"month\", one_hot=True\n)\ncovariates = year_series.stack(month_series)\ncov_train, cov_val = covariates.split_after(pd.Timestamp(\"19590101\"))\nmy_model = RNNModel(\n    model=\"LSTM\",\n    hidden_dim=20,\n    dropout=0,\n    batch_size=16,\n    n_epochs=300,\n    optimizer_kwargs={\"lr\": 1e-3},\n    model_name=\"Air_RNN\",\n    log_tensorboard=True,\n    random_state=42,\n    training_length=20,\n    input_chunk_length=14,\n    force_reset=True,\n    save_checkpoints=True,\n)\nmy_model.fit(\n    train_transformed,\n    future_covariates=covariates,\n    val_series=val_transformed,\n    val_future_covariates=covariates,\n    verbose=True,\n)\ndef eval_model(model):\n    pred_series = model.predict(n=26, future_covariates=covariates)\n    plt.figure(figsize=(8, 5))\n    series_transformed.plot(label=\"actual\")\n    pred_series.plot(label=\"forecast\")\n    plt.title(\"MAPE: {:.2f}%\".format(mape(pred_series, val_transformed)))\n    plt.legend()\n\n\neval_model(my_model)\n\nbest_model = RNNModel.load_from_checkpoint(model_name=\"Air_RNN\", best=True)\neval_model(best_model)\n\n#Backesting the RNN\nbacktest_series = my_model.historical_forecasts(\n    series_transformed,\n    future_covariates=covariates,\n    start=pd.Timestamp(\"19590101\"),\n    forecast_horizon=6,\n    retrain=False,\n    verbose=True,\n    \n#Plotting the figure\nplt.figure(figsize=(8, 5))\n#series_transformed.plot(label=\"actual\")\nbacktest_series.plot(label=\"backtest\")\nplt.legend()\nplt.title(\"Backtest, starting Jan 1959, 6-months horizon\")\nprint(\n    \"MAPE: {:.2f}%\".format(\n        mape(\n            transformer.inverse_transform(series_transformed),\n            transformer.inverse_transform(backtest_series),\n        )\n    )\n)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.259462Z","iopub.execute_input":"2022-04-01T01:44:22.259973Z","iopub.status.idle":"2022-04-01T01:44:22.313921Z","shell.execute_reply.started":"2022-04-01T01:44:22.259912Z","shell.execute_reply":"2022-04-01T01:44:22.312172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"retail_and_recreation_percent_change_from_baseline\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.31521Z","iopub.status.idle":"2022-04-01T01:44:22.315792Z","shell.execute_reply.started":"2022-04-01T01:44:22.315516Z","shell.execute_reply":"2022-04-01T01:44:22.315544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"grocery_and_pharmacy_percent_change_from_baseline\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.31862Z","iopub.status.idle":"2022-04-01T01:44:22.319092Z","shell.execute_reply.started":"2022-04-01T01:44:22.318918Z","shell.execute_reply":"2022-04-01T01:44:22.318938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"parks_percent_change_from_baseline\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.319989Z","iopub.status.idle":"2022-04-01T01:44:22.320625Z","shell.execute_reply.started":"2022-04-01T01:44:22.32036Z","shell.execute_reply":"2022-04-01T01:44:22.320387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"transit_stations_percent_change_from_baseline\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.321845Z","iopub.status.idle":"2022-04-01T01:44:22.322534Z","shell.execute_reply.started":"2022-04-01T01:44:22.322266Z","shell.execute_reply":"2022-04-01T01:44:22.322291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"workplaces_percent_change_from_baseline\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.323584Z","iopub.status.idle":"2022-04-01T01:44:22.3243Z","shell.execute_reply.started":"2022-04-01T01:44:22.324078Z","shell.execute_reply":"2022-04-01T01:44:22.324108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"new_cases\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.325504Z","iopub.status.idle":"2022-04-01T01:44:22.325908Z","shell.execute_reply.started":"2022-04-01T01:44:22.325715Z","shell.execute_reply":"2022-04-01T01:44:22.325745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### !pip install darts\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport shutil\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\n\nfrom darts import TimeSeries\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\nfrom darts.metrics import mape\nfrom darts.utils.statistics import check_seasonality, plot_acf\nfrom darts.datasets import AirPassengersDataset, SunspotsDataset\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\nfrom matplotlib import pyplot\nfrom pandas import read_csv\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport logging\n\nlogging.disable(logging.CRITICAL)\n\n\n# Read data:\n# Load birth data using read_csv\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\nprint(type(series))\n#print(series.head())\n\nseries = read_csv('../input/workingcsv/workingCSV.csv', header=0, index_col=0)\npyplot.plot(series[\"stringency_index\"])\npyplot.show()\n\n# Create training and validation sets:\n#training, validation = series.split_after(0.8)\n#model=ExplonetiaSmoothing()\n#model.fit(training)\n#pred=model.predict(len(validation))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-01T01:44:22.327469Z","iopub.status.idle":"2022-04-01T01:44:22.32804Z","shell.execute_reply.started":"2022-04-01T01:44:22.327831Z","shell.execute_reply":"2022-04-01T01:44:22.327853Z"},"trusted":true},"execution_count":null,"outputs":[]}]}